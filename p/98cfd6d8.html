<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>ChartQA | 番茄元🍅の小窝</title><meta name="author" content="tomatoyuan"><meta name="copyright" content="tomatoyuan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning  ACL 2022 code: [传送门]  0. 摘要翻译 图表在数据分析中非常受欢迎。在探索图表时，人们经常提出各种涉及多个逻辑和算术操作的复杂推理问题。他们在问题中通常还常常提到图表的视觉特征。然而，大多数现有数">
<meta property="og:type" content="article">
<meta property="og:title" content="ChartQA">
<meta property="og:url" content="https://tomatoyuan.github.io/p/98cfd6d8.html">
<meta property="og:site_name" content="番茄元🍅の小窝">
<meta property="og:description" content="ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning  ACL 2022 code: [传送门]  0. 摘要翻译 图表在数据分析中非常受欢迎。在探索图表时，人们经常提出各种涉及多个逻辑和算术操作的复杂推理问题。他们在问题中通常还常常提到图表的视觉特征。然而，大多数现有数">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://tomatoyuan.github.io/img/bg43.jpg">
<meta property="article:published_time" content="2023-12-06T01:22:48.000Z">
<meta property="article:modified_time" content="2023-12-11T00:09:25.569Z">
<meta property="article:author" content="tomatoyuan">
<meta property="article:tag" content="nlp">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tomatoyuan.github.io/img/bg43.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://tomatoyuan.github.io/p/98cfd6d8"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: tomatoyuan","link":"链接: ","source":"来源: 番茄元🍅の小窝","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'ChartQA',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-12-11 08:09:25'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/mylogo.bmp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">59</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/bg43.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">番茄元🍅の小窝</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">ChartQA</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-12-06T01:22:48.000Z" title="发表于 2023-12-06 09:22:48">2023-12-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-12-11T00:09:25.569Z" title="更新于 2023-12-11 08:09:25">2023-12-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/paper-reading/">paper_reading</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">9.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>45分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="ChartQA"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning</h1>
<blockquote>
<p>ACL 2022</p>
<p>code: [<a target="_blank" rel="noopener" href="https://github.com/vis-nlp/ChartQA">传送门</a>]</p>
</blockquote>
<h2 id="0-摘要翻译">0. 摘要翻译</h2>
<p>图表在数据分析中非常受欢迎。在探索图表时，人们经常提出各种涉及多个逻辑和算术操作的复杂推理问题。他们在问题中通常还常常提到图表的视觉特征。然而，大多数现有数据集并未专注于此类复杂推理问题，因为它们的问题是基于模板的，答案来自固定的词汇。在这项工作中，我们提出了一个大规模的基准，涵盖了9.6K个人工编写的问题，以及从人工编写的图表摘要生成的23.1K个问题。为了解决我们基准中涉及图表的视觉和逻辑推理的独特挑战，我们提出了两个基于Transformer的模型，以统一的方式结合图表的视觉特征和数据表来回答问题。虽然我们的模型在先前的数据集以及我们的基准上取得了最先进的结果，但评估也揭示了回答复杂推理问题中的若干挑战。</p>
<blockquote>
<p>吐槽一下，初步浏览了一些小标题和图表内容，感觉这文章写的漏洞百出，图表中的很多数据都算错了。。。不知道是不是我没理解，详细看完再说。</p>
</blockquote>
<h2 id="1-introduction">1. INTRODUCTION</h2>
<p>为了分析数据，需要向图表中的数据询问复杂的推理问题，这涉及到计算和逻辑操作。这种推理问题需要大量的感知和认知能力。如下图1需要计算两条折线之间每一年的差异，找出差异最大的一年。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231209134922647.png" class title="image-20231209134922647">
<p>Chart Question Answering system (ChartQA) 通过输入一张图表和一个自然语言问题来预测结果。与基于 text 的 QA 不同，ChartQA 中的图表包含视觉表示，读者的注意力可能更多在一些突出的特征，比如趋势、异常值等。对此，读者也更倾向于问出关于视觉属性的问题。如上图1中 Q2 问到了 “橘色” 折线的峰值。</p>
<p>ChartQA 的关注度逐渐增加，但是现有的数据集有很多局限性：</p>
<ol>
<li>问题是依据模板自动生成的，缺乏自然性；</li>
<li>由于图表都是用 Matplotlib 等工具生成的，无法反映真实世界图表的多样性；</li>
<li>在大多数数据集中，答案来自一个固定的小词汇表（比如局限在坐标轴的标签，yes，no 等）。这些回答忽视了，对于复杂的推理问题，需要包含大量的合并，比较等数据运算。</li>
</ol>
<p>由于大多数数据集仅支持 fixed vocabulary 的问题，所以现有的模型通常把该任务视为分类任务来处理，并且依赖于动态编码技术，其中包含根据图表元素的位置空间编码的问题和答案（例如 x-axis-label-1）。这总方法在 OCR 模型生成错误或当问题涉及到图表元素的同义词时失效。PlotQA 试图支持 open vocabulary question 通过使用 TableQA，但是没有关于图表的视觉特征。</p>
<p>为了解决上述限制，本文提出了一个大尺度 benchmark 覆盖了 9608 张人工写出的侧重于逻辑和视觉推理的问题。为了节约成本，还有 23111 个通过 T5 model 和人工总结的图表摘要（保持了语言丰富的变化）自动生成的问题，并人工验证其子集以保证质量。该 benchmark 由来自 4 个不同的 online source 的 20882 个图表组成，来确保视觉风格和主题的多样性。</p>
<p>首先使用 ChartOCR model 提取出图表中的基础数据表（underlying data table）。然后将这部分数据和使用神经网络提取的图表的视觉特征以一致的方式输入两个 基于 transformer 的 QA 模型。该 model 实现了在先前数据集上 SotA，或者用先前的 model 在新的 benchmark 上达到了和之前同等的水平。</p>
<p><strong>总结，作者的主要贡献：</strong></p>
<ol>
<li>一个大规模的 ChartQA 数据集，包含了 real-world 图表和人工编写的 question-answer pairs。</li>
<li>一个 pipeline 方法，将视觉特征和自动从图表中提取的数据 用于基于 transformer 的 QA 模型，并提供了 SotA 的结果。</li>
<li>广泛的分析了作者提出 model 的性能。</li>
</ol>
<h2 id="2-related-work">2. Related Work</h2>
<p><strong>Existing Datasets</strong></p>
<p>ChartQA 与先前的数据集有两方面不同：</p>
<ol>
<li>question 类型：human-authored vs. template-based</li>
<li>chart 来源：real-world vs. generated using a tool</li>
</ol>
<p>如下表1，FigureQA、DVQA、LEAF-QA、LEAFQA++ 使用相同的工具绘制 charts， questions 使用模板生成，answers 来自一个固定的 vocabulary。FigureQA、DVQA 使用合成的数据绘制 charts，LEAF-QA 和 LEAFQA++ 使用真实的数据绘制 charts。PlotQA 是唯一一个使用 open-vocabulary questions 的数据集，需要对底层数据应用合并操作，但是仍然是基于模板生成的。PlotQA 没有视觉上的 reasoning questions，且 charts 是使用软件绘制的。作者发现暂时没有大规模的 ChartQA 数据集，此为动机。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231207154752984.png" class title="image-20231207154752984">
<p><strong>Existing Models</strong></p>
<p>关于 ChartQA 可以分为两类：</p>
<ol>
<li>
<p>使用基于分类的视觉 QA model</p>
<p>只能处理固定词汇的问题。</p>
<p>使用编码器将问题和图表图像编码。在进入分类层前，使用 attention 机制融合前面的 question 和 chart 的编码特征。这些模型通常使用动态编码方法，对图表图像中的文本元素的位置信息进行对应的问题编码。容易引入 OCR 噪声。</p>
</li>
<li>
<p>使用 table QA 方法</p>
<p>该方法需要假设表格数据已经被给定了，或者通过视觉方法提取 chart image 中的表格数据。</p>
</li>
</ol>
<p><strong>Chart Data Extraction</strong></p>
<p>之前提出的半自动或者全自动系统从图标图像中提取数据，但是他们的方法依赖于各种启发式，并不适用于真实数据，表现仍然受限。</p>
<p>WACV 全自动的从真实图表中提取数据，并取得了不错的效果。但是这个模型仅能预测被标记的原始值(raw data value)，并不与其图例和坐标轴相关联。本文扩展了 WACV 流程，可以提取全结构的数据表，然后传入本文提出的模型。</p>
<h2 id="3-chartqa-datasets">3. ChartQA Datasets</h2>
<h3 id="3-1-data-collection-preparation">3.1 Data Collection &amp; Preparation</h3>
<p>取自四个图表网站，包含不同的主题和多样的风格。网站中包含 underlying data table 的内容也能爬的都爬了。</p>
<h3 id="3-2-data-annotation">3.2 Data Annotation</h3>
<p>两种主要的标注方法：</p>
<ol>
<li>
<p>使用 AMT（Amazon Mechanical Turk）收集人工编写的 QA 对。</p>
<p>人工标记组合问题（至少包含两种运算）和视觉问题。</p>
</li>
<li>
<p>从 Statista 的人工编写的   中生成 QA 对。</p>
</li>
</ol>
<p>数据集的拆分情况：</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231207205504603.png" class title="image-20231207205504603">
<h3 id="3-3-dataset-analysis">3.3 Dataset Analysis</h3>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231207205315772.png" class title="image-20231207205315772">
<p>如下表 4 该 benchmark 分为 4 类：</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231207205410263.png" class title="image-20231207205410263">
<h2 id="4-method">4. Method</h2>
<h3 id="4-1-problem-formulation-data-extraction">4.1 Problem Formulation &amp; Data Extraction</h3>
<p>ChartQA 的整个处理过程如下图2所示：</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231207205617236.png" class title="image-20231207205617236">
<p>考虑两种问题设定：</p>
<ol>
<li>
<p>假设图表的底层数据表格是可用的；</p>
<p>给定 N 个例子的数据集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>c</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>t</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>q</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>i</mi></msub><msubsup><mo stretchy="false">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathcal{D} = \{c_i, t_i, q_i, a_i\}_{i=1}^N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0999949999999998em;vertical-align:-0.258664em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.258664em;"><span></span></span></span></span></span></span></span></span></span> ，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示 chart image，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示 underlying data table，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示基于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的问题，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">a_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示问题的答案。</p>
<p>ChartQA 基于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>t</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i, t_i, q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80952em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 预测 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">a_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 。</p>
</li>
<li>
<p>通过 StoA ChartOCR 从 chart image <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 中提取数据表格 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 。</p>
<p>ChartQA 首先通过 key-point detection networks 定位 chart image 的关键元素（比如，区域面积、标题等）和数据编码的标记（比如，bars）。然后使用每个标记检测到的关键点和轴标签来估计标记的数据值。但是它没有关联预测值和对应的文本标签（例如x轴标签）。作者扩展了他们方法，以输出完整的结构的数据表格。使用 CRAFT 模型来分辨图表元素中的文本。然后使用位置和颜色信息来关联数据值和文本标签。</p>
</li>
</ol>
<h3 id="4-2-models">4.2 Models</h3>
<p>本文的 ChartQA 建立在两个 StoA TableQA model 之上：T5 和 TAPAS。TableQA 的输入是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">q_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76508em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 。ChartQA 的输入多了从 chart image 中提炼的图像信息。T5 具有视觉变体，但是 VL-T5 和 TAPAS 没有，作者扩展了 TAPAS 以考虑视觉特征，称之为 VisionTAPAS。</p>
<ul>
<li>
<p><strong>T5</strong></p>
<p>是一个 encoder-decoder model，它利用相同的架构和损失函数将 NLP 任务统一为文本到文本生成。T5 在大量的未标记的数据集上带着自监督去噪目标进行预训练。为了在 ChartQA 任务上对 T5 进行微调，将 data table 进行 flatten （扁平化）操作后和 question 以 “Question: Question tokens Table: Flattened table tokens” 的形式，一起送入模型进行训练，以直接生成答案。</p>
</li>
<li>
<p><strong>VL-T5</strong></p>
<p>是 T5 的扩展，将视觉-语言任务(VL)统一为以多模态输入为条件的文本输出。输入由文本信息 token 和使用 Faster R-CNN 从图像中提取的对象的视觉特征组成。该模型在多个多模态任务上进行了预训练，包括语言建模、视觉问答和视觉定位。作者利用如下方式将 VL-T5 应用到 ChartQA 任务上：</p>
<p>对于文本输入，采取了与T5相同的方法，即将图表图像的数据表展平，然后与问题文本连接起来。对于视觉输入，使用带有Resnet-101作为其骨干的Mask R-CNN（He等，2017年）提取图表图像中不同标记（例如，条形、线条）的视觉特征。与原始的 VL-T5 不同，该方式提供了固定数量的对象（36个），不过元素的数量在一个图表和另一个图表之间是不同的。为了解决这个问题，作者使用零填充提取的视觉特征，使其具有固定的长度为36。</p>
</li>
<li>
<p><strong>TAPAS</strong></p>
<p>TAPAS（Herzig等，2020年）通过为行和列添加额外的位置嵌入来扩展BERT（Devlin等，2019年）体系结构，以编码表格。如图3a所示，模型的输入格式为：[CLS] 问题标记 [SEP] 展平的表格标记。除了BERT的段落和位置嵌入外，这些标记还使用表格特定的位置嵌入进行编码。该模型有两个输出头部：聚合操作头部和单元选择头部。聚合操作头部预测一个操作（例如，COUNT、SUM、AVERAGE、NONE），然后应用于由单元选择头部选择的单元值。根据操作类型，所选单元可以构成最终答案或用于推断最终答案的输入。</p>
<p>TaPas首先在来自维基百科的表格文本对上进行了 Mask 语言建模任务的预训练，其中表格单元被随机 mask，模型被训练以预测它们。然后，它以弱监督的方式进行微调（只使用答案作为监督），采用端到端可微的目标。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231207224655577.png" class title="image-20231207224655577">
</li>
<li>
<p><strong>VisionTaPas</strong></p>
<p>TaPas 的扩展。它由三个主要组件组成：</p>
<p>用于编码图表图像的视觉Transformer编码器；用于编码问题和数据表的TaPas编码器；以及一个跨模态编码器（图3b）。</p>
</li>
<li>
<p><strong>Vision Transformer or ViT</strong></p>
<p>Vision Transformer或ViT（Dosovitskiy等，2021年）在视觉任务中采用了Transformer编码器架构（Vaswani等，2017年）。给定一张2D图表图像，图像被分割成一系列2D的补丁{p1，…，pn}。然后，每个补丁被展平并线性投影到一个d维 embeddings 向量中。为了融入补丁的位置信息，1D可学习的位置 embeddings 被添加到图像特征中。一个L层的ViT编码器产生一个表示特殊[CLS]标记和图像补丁的 embeddings 序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>=</mo><mrow><msubsup><mi>h</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow><mi>L</mi></msubsup><mtext>，</mtext><msubsup><mi>h</mi><mn>1</mn><mi>L</mi></msubsup><mtext>，</mtext><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mtext>，</mtext><msubsup><mi>h</mi><mi>n</mi><mi>L</mi></msubsup></mrow></mrow><annotation encoding="application/x-tex">H = {h^L_{cls}，h^L_1，...，h^L_n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1244389999999997em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">s</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span>。我们使用来自Dosovitskiy等（2021年）的预训练权重初始化ViT模块。</p>
<p>TaPas编码器的使用方式与上述描述相同，用于编码问题和数据表中的标记。对于一个输入标记序列{<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub><mtext>，</mtext><msub><mi>w</mi><mn>1</mn></msub><mtext>，</mtext><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mtext>，</mtext><msub><mi>w</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">w_{cls}，w_1，...，w_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>}，一个L层的TaPas生成相应的编码Z ={<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>z</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow><mi>L</mi></msubsup><mtext>，</mtext><msubsup><mi>z</mi><mn>1</mn><mi>L</mi></msubsup><mtext>，</mtext><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mtext>，</mtext><msubsup><mi>z</mi><mi>m</mi><mi>L</mi></msubsup></mrow><annotation encoding="application/x-tex">z^L_{cls}，z^L_1，...，z^L_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1244389999999997em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4168920000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">s</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4518920000000004em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">，</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord cjk_fallback">，</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>}。该模块使用在WikiTQ数据集上（Pasupat和Liang，2015年）预训练的TaPas权重进行初始化（Herzig等，2020年）。</p>
<p>跨模态编码器接收ViT和TaPas编码器的输出（H和Z）并计算多模态编码。它有四个块，每个块包含一个视觉分支和一个文本-表格分支。输入首先通过并行的多头交叉注意力层，其中在视觉分支中，查询向量是视觉特征，而键和上下文向量是文本-表格特征，在文本-表格分支中，查询向量是文本特征，键和上下文向量也是文本-表格特征。然后，交叉注意力的特征经过自注意力层和全连接层。与Transformer模型类似，每一层都应用层归一化（Ba等，2016年）并包含一个残差连接。最后，我们将TaPas的聚合操作和单元选择头添加到文本-表格分支的最终层。</p>
</li>
<li>
<p>Extension to Other Operations</p>
<p>我们ChartQA数据集中的许多问题需要执行减法或比率运算，而原始的TaPas模型不支持这些操作。因此，我们扩展了操作头以添加这两种操作（图3b）。然而，与在TaPas中基于最终答案弱监督训练它们不同，我们发现当为其提供更直接但可能带有噪声的单元监督时效果更好。我们依赖一些启发式方法在我们的训练数据中生成这种监督。例如，给定一个问题&quot; A 和 B 之间的差异是多少？&quot;，答案是5，数据值是&quot;3, 6, 8&quot;，我们寻找两个值，它们的差异是5（即8和3）。虽然这可能会产生噪声监督，但类似的方法已成功地用于向神经模型注入推理能力（Geva等，2020年；Saxton等，2019年）；在100个这样的问题的随机样本中，手动检查显示我们的启发式方法产生了24%的噪声。为了处理固定词汇的答案（例如’是’，‘否’），我们进一步扩展了操作头以包括这些类别。</p>
</li>
</ul>
<h2 id="5-evaluation">5. Evaluation</h2>
<h3 id="5-1-datasets-baselines-metrics">5.1 Datasets, Baselines &amp; Metrics</h3>
<p>与 PREFIL 和 PLOTQA* 在先前的三个数据集 FigureQA，PlotQA，DVQA 和本文提出的 ChartQA dataset 上进行比较。</p>
<ul>
<li>
<p>PREFIL 是同时融合 question 和 image features 的分类方法，然后将 features 传播到最终分类层。</p>
</li>
<li>
<p>PLOTQA 本来没有视觉特征的输入，作者对其进行了扩展。由于它对数据的提取，不能很好的适应真实图表数据，所以实验中提取 underlying data table 用到的是本文 4.1 中提到的提取方法。</p>
</li>
</ul>
<p>评估标准是宽松的，认为与 gold answer 的差距在 5% 之内，就是正确的。对于非数字答案，仍然需要一个完全匹配来考虑正确答案。</p>
<h3 id="5-2-results">5.2 Results</h3>
<h3 id="5-3-ablation-studies">5.3 Ablation Studies</h3>
<h3 id="5-4-qualitative-analysis">5.4 Qualitative Analysis</h3>
<h2 id="6-conclusion">6. Conclusion</h2>
<p>本文提出了一个新的大规模 benchmark ，使用关注于视觉和逻辑推理的人工编写的问题。评估发现这种方法很有前景，但是展示出了一些人类提出的视觉和逻辑推理问题的几个独特挑战，这几个挑战表现出语言的非正式性、复杂和细微差别。</p>
<h2 id="需要补充的">需要补充的</h2>
<ul>
<li>
<p>PlotQA：<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231207144359433.png" class title="image-20231207144359433"></p>
</li>
<li>
<p>Mask RCNN</p>
</li>
<li>
<p>TaPas</p>
</li>
<li>
<p>VisionTaPas</p>
</li>
<li>
<p>VIT</p>
</li>
<li>
<p>T5：【<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1u14y1B7WF/?spm_id_from=333.337.search-card.all.click&amp;vd_source=e7300d5accad8932a257efb8871bb9ee">视频讲解</a>】【<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Kp4y137ar/?spm_id_from=333.337.search-card.all.click&amp;vd_source=e7300d5accad8932a257efb8871bb9ee">代码实现</a>】</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231207144429237.png" class title="image-20231207144429237">
</li>
<li>
<p>ChartOCR<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231207151337628.png" class title="image-20231207151337628"></p>
</li>
<li>
<p>CRAF<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/p/98cfd6d8/image-20231207213803365.png" class title="image-20231207213803365"></p>
</li>
</ul>
<h2 id="7-代码复现">7. 代码复现</h2>
<h3 id="7-1-环境配置">7.1 环境配置</h3>
<p>刚拿到 SCIR 的 hpc，得配置一下 anaconda ，修改一下 conda 源和 pip 源。</p>
<h4 id="conda-换源">conda 换源</h4>
<p>将以上配置文件写在<code>~/.condarc</code>中<br>
<code>vim ~/.condarc</code></p>
<p>清华源：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">ssl_verify: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>工大源：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">ssl_verify: true</span><br></pre></td></tr></table></figure>
<p>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/87123943">https://zhuanlan.zhihu.com/p/87123943</a></p>
<h4 id="pip-换源">pip 换源</h4>
<p>安装 pytorch 用 pip3 安装更快。pip 换源：</p>
<p>1.在根目录下创建.pip文件夹</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> ~/.pip</span><br></pre></td></tr></table></figure>
<p>2.在创建好的.pip文件夹下创建pip源配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">touch</span> ~/.pip/pip.conf</span><br></pre></td></tr></table></figure>
<p>3.使用vim打开pip.conf配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.pip/pip.conf</span><br></pre></td></tr></table></figure>
<p>4.添加下述内容</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></table></figure>
<p>5.保存并退出</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:wq</span><br></pre></td></tr></table></figure>
<p>以上就完成了pip源的配置过程。</p>
<blockquote>
<p>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_44716044/article/details/123347432">https://blog.csdn.net/qq_44716044/article/details/123347432</a></p>
</blockquote>
<h3 id="7-2-t5复现">7.2 T5复现</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br></pre></td><td class="code"><pre><span class="line">qyfan@gpu12:~/code/ChartQA-main$ <span class="built_in">source</span> activate</span><br><span class="line">(base) qyfan@gpu12:~/code/ChartQA-main$ conda activate ChartQA</span><br><span class="line">(ChartQA) qyfan@gpu12:~/code/ChartQA-main$ <span class="built_in">ls</span></span><br><span class="line">ChartQA-Dataset  Data-Extraction  Figures-and-Examples  LICENSE  Models  README.md</span><br><span class="line">(ChartQA) qyfan@gpu12:~/code/ChartQA-main$ <span class="built_in">cd</span> Models/T5/</span><br><span class="line">(ChartQA) qyfan@gpu12:~/code/ChartQA-main/Models/T5$ sh train_test.sh </span><br><span class="line">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span><br><span class="line">[nltk_data]     refused&gt;</span><br><span class="line">12/09/2023 23:24:52 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False</span><br><span class="line">Downloading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 6693.04it/s]</span><br><span class="line">Extracting data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 23.16it/s]</span><br><span class="line">Generating train <span class="built_in">split</span>: 29999 examples [00:00, 87931.53 examples/s]</span><br><span class="line">Generating validation <span class="built_in">split</span>: 29999 examples [00:00, 114942.30 examples/s]</span><br><span class="line">Generating <span class="built_in">test</span> <span class="built_in">split</span>: 29999 examples [00:00, 162474.66 examples/s]</span><br><span class="line">/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 <span class="built_in">which</span> will be corrected <span class="keyword">in</span> Transformers v5.</span><br><span class="line">For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.</span><br><span class="line">- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.</span><br><span class="line">- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.</span><br><span class="line">- To avoid this warning, please instantiate this tokenizer with `model_max_length` <span class="built_in">set</span> to your preferred value.</span><br><span class="line">  warnings.warn(</span><br><span class="line">Running tokenizer on train dataset:   0%|                                                                                         | 0/29999 [00:00&lt;?, ? examples/s]/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed <span class="keyword">in</span> v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either <span class="keyword">in</span> the same call as your input texts <span class="keyword">if</span> you use the same keyword arguments, or <span class="keyword">in</span> a separate call.</span><br><span class="line">  warnings.warn(</span><br><span class="line">Running tokenizer on train dataset: 100%|███████████████████████████████████████████████████████████████████████████| 29999/29999 [00:10&lt;00:00, 2997.48 examples/s]</span><br><span class="line">Running tokenizer on validation dataset: 100%|██████████████████████████████████████████████████████████████████████| 29999/29999 [00:09&lt;00:00, 3049.45 examples/s]</span><br><span class="line">Running tokenizer on prediction dataset: 100%|██████████████████████████████████████████████████████████████████████| 29999/29999 [00:09&lt;00:00, 3022.47 examples/s]</span><br><span class="line">  0%|                                                                                                                                   | 0/112500 [00:00&lt;?, ?it/s][WARNING|logging.py:314] 2023-12-09 23:25:31,991 &gt;&gt; You<span class="string">&#x27;re using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.</span></span><br><span class="line"><span class="string">[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())</span></span><br><span class="line"><span class="string">&#123;&#x27;</span>loss<span class="string">&#x27;: 1.2697, &#x27;</span>learning_rate<span class="string">&#x27;: 9.955555555555556e-05, &#x27;</span>epoch<span class="string">&#x27;: 0.13&#125;                                                                                            </span></span><br><span class="line"><span class="string">&#123;&#x27;</span>loss<span class="string">&#x27;: 1.0826, &#x27;</span>learning_rate<span class="string">&#x27;: 9.911111111111112e-05, &#x27;</span>epoch<span class="string">&#x27;: 0.27&#125;                                                                                            </span></span><br><span class="line"><span class="string">  1%|█▏                                                                                                                    | 1076/112500 [03:08&lt;5:3  1%|▉                                                                                                     | 1077/112500 [03:08&lt;5:29:15,  5.64it/s]&#123;&#x27;</span>loss<span class="string">&#x27;: 0.9864, &#x27;</span>learning_rate<span class="string">&#x27;: 9.866666666666668e-05, &#x27;</span>epoch<span class="string">&#x27;: 0.4&#125;                                                                             </span></span><br><span class="line"><span class="string">&#123;&#x27;</span>loss<span class="string">&#x27;: 0.9707, &#x27;</span>learning_rate<span class="string">&#x27;: 9.822222222222223e-05, &#x27;</span>epoch<span class="string">&#x27;: 0.53&#125;                                                                            </span></span><br><span class="line"><span class="string">  2%|█▊                                                                                                    | 2000/112500 [05:50&lt;5:31:17,  5.56it/s]/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.</span></span><br><span class="line"><span class="string">  warnings.warn(</span></span><br><span class="line"><span class="string">                                                                                                                                                  Traceback (most recent call last):██████████████████████████████████████████████████████████████████████████████| 1875/1875 [09:56&lt;00:00,  3.92it/s]</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;, line 647, in &lt;module&gt;</span></span><br><span class="line"><span class="string">    main()</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;, line 569, in main</span></span><br><span class="line"><span class="string">    train_result = trainer.train(resume_from_checkpoint=checkpoint)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer.py&quot;, line 1555, in train</span></span><br><span class="line"><span class="string">    return inner_training_loop(</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer.py&quot;, line 1922, in _inner_training_loop</span></span><br><span class="line"><span class="string">    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer.py&quot;, line 2271, in _maybe_log_save_evaluate</span></span><br><span class="line"><span class="string">    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer_seq2seq.py&quot;, line 165, in evaluate</span></span><br><span class="line"><span class="string">    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer.py&quot;, line 3011, in evaluate</span></span><br><span class="line"><span class="string">    output = eval_loop(</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer.py&quot;, line 3304, in evaluation_loop</span></span><br><span class="line"><span class="string">    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;, line 541, in compute_metrics</span></span><br><span class="line"><span class="string">    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;, line 525, in postprocess_text</span></span><br><span class="line"><span class="string">    preds = [&quot;\n&quot;.join(nltk.sent_tokenize(pred)) for pred in preds]</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;, line 525, in &lt;listcomp&gt;</span></span><br><span class="line"><span class="string">    preds = [&quot;\n&quot;.join(nltk.sent_tokenize(pred)) for pred in preds]</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/nltk/tokenize/__init__.py&quot;, line 106, in sent_tokenize</span></span><br><span class="line"><span class="string">    tokenizer = load(f&quot;tokenizers/punkt/&#123;language&#125;.pickle&quot;)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/nltk/data.py&quot;, line 750, in load</span></span><br><span class="line"><span class="string">    opened_resource = _open(resource_url)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/nltk/data.py&quot;, line 876, in _open</span></span><br><span class="line"><span class="string">    return find(path_, path + [&quot;&quot;]).open()</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/nltk/data.py&quot;, line 583, in find</span></span><br><span class="line"><span class="string">    raise LookupError(resource_not_found)</span></span><br><span class="line"><span class="string">LookupError: </span></span><br><span class="line"><span class="string">**********************************************************************</span></span><br><span class="line"><span class="string">  Resource punkt not found.</span></span><br><span class="line"><span class="string">  Please use the NLTK Downloader to obtain the resource:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &gt;&gt;&gt; import nltk</span></span><br><span class="line"><span class="string">  &gt;&gt;&gt; nltk.download(&#x27;</span>punkt<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  For more information see: https://www.nltk.org/data.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Attempted to load tokenizers/punkt/PY3/english.pickle</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Searched in:</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/local/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/local/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span><span class="string">&#x27;</span></span><br><span class="line"><span class="string">**********************************************************************</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  2%|█▊                                                                                                   | 2000/112500 [15:47&lt;14:32:20,  2.11it/s]</span></span><br><span class="line"><span class="string">                                                                                                                                                  [2023-12-09 23:41:22,421] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2406783) of binary: /home/qyfan/anaconda3/envs/ChartQA/bin/python</span></span><br><span class="line"><span class="string">Traceback (most recent call last):</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/runpy.py&quot;, line 197, in _run_module_as_main</span></span><br><span class="line"><span class="string">    return _run_code(code, main_globals, None,</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/runpy.py&quot;, line 87, in _run_code</span></span><br><span class="line"><span class="string">    exec(code, run_globals)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/run.py&quot;, line 810, in &lt;module&gt;</span></span><br><span class="line"><span class="string">    main()</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py&quot;, line 346, in wrapper</span></span><br><span class="line"><span class="string">    return f(*args, **kwargs)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/run.py&quot;, line 806, in main</span></span><br><span class="line"><span class="string">    run(args)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/run.py&quot;, line 797, in run</span></span><br><span class="line"><span class="string">    elastic_launch(</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/launcher/api.py&quot;, line 134, in __call__</span></span><br><span class="line"><span class="string">    return launch_agent(self._config, self._entrypoint, list(args))</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/launcher/api.py&quot;, line 264, in launch_agent</span></span><br><span class="line"><span class="string">    raise ChildFailedError(</span></span><br><span class="line"><span class="string">torch.distributed.elastic.multiprocessing.errors.ChildFailedError: </span></span><br><span class="line"><span class="string">============================================================</span></span><br><span class="line"><span class="string">run_T5.py FAILED</span></span><br><span class="line"><span class="string">------------------------------------------------------------</span></span><br><span class="line"><span class="string">Failures:</span></span><br><span class="line"><span class="string">  &lt;NO_OTHER_FAILURES&gt;</span></span><br><span class="line"><span class="string">------------------------------------------------------------</span></span><br><span class="line"><span class="string">Root Cause (first observed failure):</span></span><br><span class="line"><span class="string">[0]:</span></span><br><span class="line"><span class="string">  time      : 2023-12-09_23:41:22</span></span><br><span class="line"><span class="string">  host      : gpu12.cluster.com</span></span><br><span class="line"><span class="string">  rank      : 0 (local_rank: 0)</span></span><br><span class="line"><span class="string">  exitcode  : 1 (pid: 2406783)</span></span><br><span class="line"><span class="string">  error_file: &lt;N/A&gt;</span></span><br><span class="line"><span class="string">  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html</span></span><br><span class="line"><span class="string">============================================================</span></span><br><span class="line"><span class="string">(ChartQA) qyfan@gpu12:~/code/ChartQA-main/Models/T5$ python</span></span><br><span class="line"><span class="string">Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) </span></span><br><span class="line"><span class="string">[GCC 12.3.0] on linux</span></span><br><span class="line"><span class="string">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; import nltk</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; exit()</span></span><br><span class="line"><span class="string">(ChartQA) qyfan@gpu12:~/code/ChartQA-main/Models/T5$ python</span></span><br><span class="line"><span class="string">Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) </span></span><br><span class="line"><span class="string">[GCC 12.3.0] on linux</span></span><br><span class="line"><span class="string">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; import nltk</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; srun: Job step aborted: Waiting up to 32 seconds for job step to finish.</span></span><br><span class="line"><span class="string">slurmstepd-gpu12: error: *** STEP 60242.0 ON gpu12 CANCELLED AT 2023-12-09T23:52:55 DUE TO TIME LIMIT ***</span></span><br><span class="line"><span class="string">srun: error: gpu12: task 0: Killed</span></span><br><span class="line"><span class="string">qyfan@hpc-login-01:~/code/ChartQA-main$ cd Models/</span></span><br><span class="line"><span class="string">qyfan@hpc-login-01:~/code/ChartQA-main/Models$ cd T5/</span></span><br><span class="line"><span class="string">qyfan@hpc-login-01:~/code/ChartQA-main/Models/T5$ ls</span></span><br><span class="line"><span class="string">predict_test.sh  result  run_T5.py  t5-base  train_test.sh</span></span><br><span class="line"><span class="string">qyfan@hpc-login-01:~/code/ChartQA-main/Models/T5$ wget https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/tokenizers/punkt.zip</span></span><br><span class="line"><span class="string">--2023-12-09 23:53:58--  https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/tokenizers/punkt.zip</span></span><br><span class="line"><span class="string">Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 0.0.0.0, ::</span></span><br><span class="line"><span class="string">Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|0.0.0.0|:443... failed: Connection refused.</span></span><br><span class="line"><span class="string">Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|::|:443... failed: Connection refused.</span></span><br><span class="line"><span class="string">qyfan@hpc-login-01:~/code/ChartQA-main/Models/T5$ pwd</span></span><br><span class="line"><span class="string">/home/qyfan/code/ChartQA-main/Models/T5</span></span><br><span class="line"><span class="string">qyfan@hpc-login-01:~/code/ChartQA-main/Models/T5$ source activate</span></span><br><span class="line"><span class="string">(base) qyfan@hpc-login-01:~/code/ChartQA-main/Models/T5$ conda activate ChartQA</span></span><br><span class="line"><span class="string">(ChartQA) qyfan@hpc-login-01:~/code/ChartQA-main/Models/T5$ ls</span></span><br><span class="line"><span class="string">predict_test.sh  punkt  result  run_T5.py  t5-base  train_test.sh</span></span><br><span class="line"><span class="string">(ChartQA) qyfan@hpc-login-01:~/code/ChartQA-main/Models/T5$ python</span></span><br><span class="line"><span class="string">Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) </span></span><br><span class="line"><span class="string">[GCC 12.3.0] on linux</span></span><br><span class="line"><span class="string">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; import nltk</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.download(&quot;punkt&quot;)</span></span><br><span class="line"><span class="string">[nltk_data] Error loading punkt: &lt;urlopen error [Errno 111] Connection</span></span><br><span class="line"><span class="string">[nltk_data]     refused&gt;</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.data.find(&quot;tokenizers/punkt&quot;)</span></span><br><span class="line"><span class="string">Traceback (most recent call last):</span></span><br><span class="line"><span class="string">  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/nltk/data.py&quot;, line 583, in find</span></span><br><span class="line"><span class="string">    raise LookupError(resource_not_found)</span></span><br><span class="line"><span class="string">LookupError: </span></span><br><span class="line"><span class="string">**********************************************************************</span></span><br><span class="line"><span class="string">  Resource punkt not found.</span></span><br><span class="line"><span class="string">  Please use the NLTK Downloader to obtain the resource:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &gt;&gt;&gt; import nltk</span></span><br><span class="line"><span class="string">  &gt;&gt;&gt; nltk.download(&#x27;</span>punkt<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  For more information see: https://www.nltk.org/data.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Attempted to load tokenizers/punkt</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Searched in:</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/local/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/local/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">**********************************************************************</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&gt;&gt;&gt; /home/qyfan/nltk_data</span></span><br><span class="line"><span class="string">  File &quot;&lt;stdin&gt;&quot;, line 1</span></span><br><span class="line"><span class="string">    /home/qyfan/nltk_data</span></span><br><span class="line"><span class="string">    ^</span></span><br><span class="line"><span class="string">SyntaxError: invalid syntax</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.data.find(&quot;tokenizers/punkt&quot;)</span></span><br><span class="line"><span class="string">Traceback (most recent call last):</span></span><br><span class="line"><span class="string">  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/nltk/data.py&quot;, line 583, in find</span></span><br><span class="line"><span class="string">    raise LookupError(resource_not_found)</span></span><br><span class="line"><span class="string">LookupError: </span></span><br><span class="line"><span class="string">**********************************************************************</span></span><br><span class="line"><span class="string">  Resource punkt not found.</span></span><br><span class="line"><span class="string">  Please use the NLTK Downloader to obtain the resource:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &gt;&gt;&gt; import nltk</span></span><br><span class="line"><span class="string">  &gt;&gt;&gt; nltk.download(&#x27;</span>punkt<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  For more information see: https://www.nltk.org/data.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Attempted to load tokenizers/punkt</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Searched in:</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/local/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/local/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">**********************************************************************</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&gt;&gt;&gt; /home/qyfan/nltk_data</span></span><br><span class="line"><span class="string">KeyboardInterrupt</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.data.find(&quot;tokenizers/punkt&quot;)</span></span><br><span class="line"><span class="string">Traceback (most recent call last):</span></span><br><span class="line"><span class="string">  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/nltk/data.py&quot;, line 583, in find</span></span><br><span class="line"><span class="string">    raise LookupError(resource_not_found)</span></span><br><span class="line"><span class="string">LookupError: </span></span><br><span class="line"><span class="string">**********************************************************************</span></span><br><span class="line"><span class="string">  Resource punkt not found.</span></span><br><span class="line"><span class="string">  Please use the NLTK Downloader to obtain the resource:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  &gt;&gt;&gt; import nltk</span></span><br><span class="line"><span class="string">  &gt;&gt;&gt; nltk.download(&#x27;</span>punkt<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">  For more information see: https://www.nltk.org/data.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Attempted to load tokenizers/punkt</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Searched in:</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/home/qyfan/anaconda3/envs/ChartQA/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/local/share/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">    - &#x27;</span>/usr/local/lib/nltk_data<span class="string">&#x27;</span></span><br><span class="line"><span class="string">**********************************************************************</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&gt;&gt;&gt; exit()</span></span><br><span class="line"><span class="string">(ChartQA) qyfan@hpc-login-01:~/code/ChartQA-main/Models/T5$ python</span></span><br><span class="line"><span class="string">Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) </span></span><br><span class="line"><span class="string">[GCC 12.3.0] on linux</span></span><br><span class="line"><span class="string">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; import nltk</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; nltk.data.find(&quot;./punkt&quot;)</span></span><br><span class="line"><span class="string">FileSystemPathPointer(&#x27;</span>/home/qyfan/nltk_data/punkt<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; exit()</span></span><br><span class="line"><span class="string">(ChartQA) qyfan@hpc-login-01:~/code/ChartQA-main/Models/T5$ srun --gres=gpu:tesla_v100s-pcie-32gb:1 --pty bash -i</span></span><br><span class="line"><span class="string">qyfan@gpu12:~/code/ChartQA-main/Models/T5$ source activate</span></span><br><span class="line"><span class="string">(base) qyfan@gpu12:~/code/ChartQA-main/Models/T5$ conda activate ChartQA</span></span><br><span class="line"><span class="string">(ChartQA) qyfan@gpu12:~/code/ChartQA-main/Models/T5$ sh predict_test.sh </span></span><br><span class="line"><span class="string">model_arg: ModelArguments(model_name_or_path=&#x27;</span>t5-base<span class="string">&#x27;, config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision=&#x27;</span>main<span class="string">&#x27;, use_auth_token=False, resize_position_embeddings=None)</span></span><br><span class="line"><span class="string">data_args: DataTrainingArguments(dataset_name=None, dataset_config_name=None, text_column=&#x27;</span>Input<span class="string">&#x27;, summary_column=&#x27;</span>Output<span class="string">&#x27;, train_file=None, validation_file=None, test_file=&#x27;</span>/home/qyfan/code/ChartQA-main/Figures-and-Examples/T5andVL-T5InputFileExamples.csv<span class="string">&#x27;, overwrite_cache=False, preprocessing_num_workers=None, max_source_length=512, max_target_length=128, val_max_target_length=128, pad_to_max_length=False, max_train_samples=None, max_eval_samples=None, max_predict_samples=None, num_beams=None, ignore_pad_token_for_loss=True, source_prefix=&#x27;</span><span class="string">&#x27;)</span></span><br><span class="line"><span class="string">training_args Seq2SeqTrainingArguments(</span></span><br><span class="line"><span class="string">_n_gpu=1,</span></span><br><span class="line"><span class="string">adafactor=False,</span></span><br><span class="line"><span class="string">adam_beta1=0.9,</span></span><br><span class="line"><span class="string">adam_beta2=0.999,</span></span><br><span class="line"><span class="string">adam_epsilon=1e-08,</span></span><br><span class="line"><span class="string">auto_find_batch_size=False,</span></span><br><span class="line"><span class="string">bf16=False,</span></span><br><span class="line"><span class="string">bf16_full_eval=False,</span></span><br><span class="line"><span class="string">data_seed=None,</span></span><br><span class="line"><span class="string">dataloader_drop_last=False,</span></span><br><span class="line"><span class="string">dataloader_num_workers=0,</span></span><br><span class="line"><span class="string">dataloader_pin_memory=True,</span></span><br><span class="line"><span class="string">ddp_backend=None,</span></span><br><span class="line"><span class="string">ddp_broadcast_buffers=None,</span></span><br><span class="line"><span class="string">ddp_bucket_cap_mb=None,</span></span><br><span class="line"><span class="string">ddp_find_unused_parameters=None,</span></span><br><span class="line"><span class="string">ddp_timeout=1800,</span></span><br><span class="line"><span class="string">debug=[],</span></span><br><span class="line"><span class="string">deepspeed=None,</span></span><br><span class="line"><span class="string">disable_tqdm=False,</span></span><br><span class="line"><span class="string">dispatch_batches=None,</span></span><br><span class="line"><span class="string">do_eval=False,</span></span><br><span class="line"><span class="string">do_predict=True,</span></span><br><span class="line"><span class="string">do_train=False,</span></span><br><span class="line"><span class="string">eval_accumulation_steps=None,</span></span><br><span class="line"><span class="string">eval_delay=0,</span></span><br><span class="line"><span class="string">eval_steps=None,</span></span><br><span class="line"><span class="string">evaluation_strategy=no,</span></span><br><span class="line"><span class="string">fp16=False,</span></span><br><span class="line"><span class="string">fp16_backend=auto,</span></span><br><span class="line"><span class="string">fp16_full_eval=False,</span></span><br><span class="line"><span class="string">fp16_opt_level=O1,</span></span><br><span class="line"><span class="string">fsdp=[],</span></span><br><span class="line"><span class="string">fsdp_config=&#123;&#x27;</span>min_num_params<span class="string">&#x27;: 0, &#x27;</span>xla<span class="string">&#x27;: False, &#x27;</span>xla_fsdp_grad_ckpt<span class="string">&#x27;: False&#125;,</span></span><br><span class="line"><span class="string">fsdp_min_num_params=0,</span></span><br><span class="line"><span class="string">fsdp_transformer_layer_cls_to_wrap=None,</span></span><br><span class="line"><span class="string">full_determinism=False,</span></span><br><span class="line"><span class="string">generation_config=None,</span></span><br><span class="line"><span class="string">generation_max_length=None,</span></span><br><span class="line"><span class="string">generation_num_beams=None,</span></span><br><span class="line"><span class="string">gradient_accumulation_steps=1,</span></span><br><span class="line"><span class="string">gradient_checkpointing=False,</span></span><br><span class="line"><span class="string">gradient_checkpointing_kwargs=None,</span></span><br><span class="line"><span class="string">greater_is_better=None,</span></span><br><span class="line"><span class="string">group_by_length=False,</span></span><br><span class="line"><span class="string">half_precision_backend=auto,</span></span><br><span class="line"><span class="string">hub_always_push=False,</span></span><br><span class="line"><span class="string">hub_model_id=None,</span></span><br><span class="line"><span class="string">hub_private_repo=False,</span></span><br><span class="line"><span class="string">hub_strategy=every_save,</span></span><br><span class="line"><span class="string">hub_token=&lt;HUB_TOKEN&gt;,</span></span><br><span class="line"><span class="string">ignore_data_skip=False,</span></span><br><span class="line"><span class="string">include_inputs_for_metrics=False,</span></span><br><span class="line"><span class="string">include_tokens_per_second=False,</span></span><br><span class="line"><span class="string">jit_mode_eval=False,</span></span><br><span class="line"><span class="string">label_names=None,</span></span><br><span class="line"><span class="string">label_smoothing_factor=0.0,</span></span><br><span class="line"><span class="string">learning_rate=5e-05,</span></span><br><span class="line"><span class="string">length_column_name=length,</span></span><br><span class="line"><span class="string">load_best_model_at_end=False,</span></span><br><span class="line"><span class="string">local_rank=0,</span></span><br><span class="line"><span class="string">log_level=passive,</span></span><br><span class="line"><span class="string">log_level_replica=warning,</span></span><br><span class="line"><span class="string">log_on_each_node=True,</span></span><br><span class="line"><span class="string">logging_dir=result/runs/Dec10_00-28-05_gpu12,</span></span><br><span class="line"><span class="string">logging_first_step=False,</span></span><br><span class="line"><span class="string">logging_nan_inf_filter=True,</span></span><br><span class="line"><span class="string">logging_steps=500,</span></span><br><span class="line"><span class="string">logging_strategy=steps,</span></span><br><span class="line"><span class="string">lr_scheduler_type=linear,</span></span><br><span class="line"><span class="string">max_grad_norm=1.0,</span></span><br><span class="line"><span class="string">max_steps=-1,</span></span><br><span class="line"><span class="string">metric_for_best_model=None,</span></span><br><span class="line"><span class="string">mp_parameters=,</span></span><br><span class="line"><span class="string">neftune_noise_alpha=None,</span></span><br><span class="line"><span class="string">no_cuda=False,</span></span><br><span class="line"><span class="string">num_train_epochs=3.0,</span></span><br><span class="line"><span class="string">optim=adamw_torch,</span></span><br><span class="line"><span class="string">optim_args=None,</span></span><br><span class="line"><span class="string">output_dir=result,</span></span><br><span class="line"><span class="string">overwrite_output_dir=False,</span></span><br><span class="line"><span class="string">past_index=-1,</span></span><br><span class="line"><span class="string">per_device_eval_batch_size=192,</span></span><br><span class="line"><span class="string">per_device_train_batch_size=8,</span></span><br><span class="line"><span class="string">predict_with_generate=True,</span></span><br><span class="line"><span class="string">prediction_loss_only=False,</span></span><br><span class="line"><span class="string">push_to_hub=False,</span></span><br><span class="line"><span class="string">push_to_hub_model_id=None,</span></span><br><span class="line"><span class="string">push_to_hub_organization=None,</span></span><br><span class="line"><span class="string">push_to_hub_token=&lt;PUSH_TO_HUB_TOKEN&gt;,</span></span><br><span class="line"><span class="string">ray_scope=last,</span></span><br><span class="line"><span class="string">remove_unused_columns=True,</span></span><br><span class="line"><span class="string">report_to=[],</span></span><br><span class="line"><span class="string">resume_from_checkpoint=None,</span></span><br><span class="line"><span class="string">run_name=result,</span></span><br><span class="line"><span class="string">save_on_each_node=False,</span></span><br><span class="line"><span class="string">save_safetensors=True,</span></span><br><span class="line"><span class="string">save_steps=500,</span></span><br><span class="line"><span class="string">save_strategy=steps,</span></span><br><span class="line"><span class="string">save_total_limit=None,</span></span><br><span class="line"><span class="string">seed=42,</span></span><br><span class="line"><span class="string">skip_memory_metrics=True,</span></span><br><span class="line"><span class="string">sortish_sampler=False,</span></span><br><span class="line"><span class="string">split_batches=False,</span></span><br><span class="line"><span class="string">tf32=None,</span></span><br><span class="line"><span class="string">torch_compile=False,</span></span><br><span class="line"><span class="string">torch_compile_backend=None,</span></span><br><span class="line"><span class="string">torch_compile_mode=None,</span></span><br><span class="line"><span class="string">torchdynamo=None,</span></span><br><span class="line"><span class="string">tpu_metrics_debug=False,</span></span><br><span class="line"><span class="string">tpu_num_cores=None,</span></span><br><span class="line"><span class="string">use_cpu=False,</span></span><br><span class="line"><span class="string">use_ipex=False,</span></span><br><span class="line"><span class="string">use_legacy_prediction_loop=False,</span></span><br><span class="line"><span class="string">use_mps_device=False,</span></span><br><span class="line"><span class="string">warmup_ratio=0.0,</span></span><br><span class="line"><span class="string">warmup_steps=0,</span></span><br><span class="line"><span class="string">weight_decay=0.0,</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">12/10/2023 00:28:05 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False</span></span><br><span class="line"><span class="string">/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.</span></span><br><span class="line"><span class="string">For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.</span></span><br><span class="line"><span class="string">- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.</span></span><br><span class="line"><span class="string">- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.</span></span><br><span class="line"><span class="string">- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.</span></span><br><span class="line"><span class="string">  warnings.warn(</span></span><br><span class="line"><span class="string">[WARNING|logging.py:314] 2023-12-10 00:28:10,765 &gt;&gt; You&#x27;</span>re using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.</span><br><span class="line">100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [10:07&lt;00:00,  2.75s/it]Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;</span>, line 650, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    main()</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;</span>, line 605, <span class="keyword">in</span> main</span><br><span class="line">    predict_results = trainer.predict(</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer_seq2seq.py&quot;</span>, line 228, <span class="keyword">in</span> predict</span><br><span class="line">    <span class="built_in">return</span> super().predict(test_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer.py&quot;</span>, line 3087, <span class="keyword">in</span> predict</span><br><span class="line">    output = eval_loop(</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer.py&quot;</span>, line 3304, <span class="keyword">in</span> evaluation_loop</span><br><span class="line">    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;</span>, line 537, <span class="keyword">in</span> compute_metrics</span><br><span class="line">    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/tokenization_utils_base.py&quot;</span>, line 3706, <span class="keyword">in</span> batch_decode</span><br><span class="line">    <span class="built_in">return</span> [</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/tokenization_utils_base.py&quot;</span>, line 3707, <span class="keyword">in</span> &lt;listcomp&gt;</span><br><span class="line">    self.decode(</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/tokenization_utils_base.py&quot;</span>, line 3746, <span class="keyword">in</span> decode</span><br><span class="line">    <span class="built_in">return</span> self._decode(</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py&quot;</span>, line 625, <span class="keyword">in</span> _decode</span><br><span class="line">    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)</span><br><span class="line">OverflowError: out of range integral <span class="built_in">type</span> conversion attempted</span><br><span class="line">100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [10:08&lt;00:00,  3.87s/it]</span><br><span class="line">[2023-12-10 00:38:28,013] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2410039) of binary: /home/qyfan/anaconda3/envs/ChartQA/bin/python</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/runpy.py&quot;</span>, line 197, <span class="keyword">in</span> _run_module_as_main</span><br><span class="line">    <span class="built_in">return</span> _run_code(code, main_globals, None,</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/runpy.py&quot;</span>, line 87, <span class="keyword">in</span> _run_code</span><br><span class="line">    <span class="built_in">exec</span>(code, run_globals)</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/run.py&quot;</span>, line 810, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    main()</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py&quot;</span>, line 346, <span class="keyword">in</span> wrapper</span><br><span class="line">    <span class="built_in">return</span> f(*args, **kwargs)</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/run.py&quot;</span>, line 806, <span class="keyword">in</span> main</span><br><span class="line">    run(args)</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/run.py&quot;</span>, line 797, <span class="keyword">in</span> run</span><br><span class="line">    elastic_launch(</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/launcher/api.py&quot;</span>, line 134, <span class="keyword">in</span> __call__</span><br><span class="line">    <span class="built_in">return</span> launch_agent(self._config, self._entrypoint, list(args))</span><br><span class="line">  File <span class="string">&quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/launcher/api.py&quot;</span>, line 264, <span class="keyword">in</span> launch_agent</span><br><span class="line">    raise ChildFailedError(</span><br><span class="line">torch.distributed.elastic.multiprocessing.errors.ChildFailedError: </span><br><span class="line">============================================================</span><br><span class="line">run_T5.py FAILED</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">Failures:</span><br><span class="line">  &lt;NO_OTHER_FAILURES&gt;</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">Root Cause (first observed failure):</span><br><span class="line">[0]:</span><br><span class="line">  time      : 2023-12-10_00:38:28</span><br><span class="line">  host      : gpu12.cluster.com</span><br><span class="line">  rank      : 0 (local_rank: 0)</span><br><span class="line">  exitcode  : 1 (pid: 2410039)</span><br><span class="line">  error_file: &lt;N/A&gt;</span><br><span class="line">  traceback : To <span class="built_in">enable</span> traceback see: https://pytorch.org/docs/stable/elastic/errors.html</span><br><span class="line">============================================================</span><br><span class="line">(ChartQA) qyfan@gpu12:~/code/ChartQA-main/Models/T5$ </span><br></pre></td></tr></table></figure>
<h4 id="bug2">bug2</h4>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><span class="line">(ChartQA) qyfan@gpu12:~/code/ChartQA-main/Models/T5$ sh predict_test.sh </span><br><span class="line">model_arg: ModelArguments(model_name_or_path=<span class="string">&#x27;t5-base&#x27;</span>, config_name=None, tokenizer_name=None, cache_dir=None, use_fast_tokenizer=True, model_revision=<span class="string">&#x27;main&#x27;</span>, use_auth_token=False, resize_position_embeddings=None)</span><br><span class="line">data_args: DataTrainingArguments(dataset_name=None, dataset_config_name=None, text_column=<span class="string">&#x27;Input&#x27;</span>, summary_column=<span class="string">&#x27;Output&#x27;</span>, train_file=None, validation_file=None, test_file=<span class="string">&#x27;/home/qyfan/code/ChartQA-main/Figures-and-Examples/T5andVL-T5InputFileExamples.csv&#x27;</span>, overwrite_cache=False, preprocessing_num_workers=None, max_source_length=128, max_target_length=128, val_max_target_length=128, pad_to_max_length=True, max_train_samples=None, max_eval_samples=None, max_predict_samples=None, num_beams=None, ignore_pad_token_for_loss=True, source_prefix=<span class="string">&#x27;summarize: &#x27;</span>)</span><br><span class="line">training_args Seq2SeqTrainingArguments(</span><br><span class="line">_n_gpu=1,</span><br><span class="line">adafactor=False,</span><br><span class="line">adam_beta1=0.9,</span><br><span class="line">adam_beta2=0.999,</span><br><span class="line">adam_epsilon=1e-08,</span><br><span class="line">auto_find_batch_size=False,</span><br><span class="line">bf16=False,</span><br><span class="line">bf16_full_eval=False,</span><br><span class="line">data_seed=None,</span><br><span class="line">dataloader_drop_last=False,</span><br><span class="line">dataloader_num_workers=0,</span><br><span class="line">dataloader_pin_memory=True,</span><br><span class="line">ddp_backend=None,</span><br><span class="line">ddp_broadcast_buffers=None,</span><br><span class="line">ddp_bucket_cap_mb=None,</span><br><span class="line">ddp_find_unused_parameters=None,</span><br><span class="line">ddp_timeout=1800,</span><br><span class="line">debug=[],</span><br><span class="line">deepspeed=None,</span><br><span class="line">disable_tqdm=False,</span><br><span class="line">dispatch_batches=None,</span><br><span class="line">do_eval=False,</span><br><span class="line">do_predict=True,</span><br><span class="line">do_train=False,</span><br><span class="line">eval_accumulation_steps=None,</span><br><span class="line">eval_delay=0,</span><br><span class="line">eval_steps=None,</span><br><span class="line">evaluation_strategy=no,</span><br><span class="line">fp16=False,</span><br><span class="line">fp16_backend=auto,</span><br><span class="line">fp16_full_eval=False,</span><br><span class="line">fp16_opt_level=O1,</span><br><span class="line">fsdp=[],</span><br><span class="line">fsdp_config=&#123;<span class="string">&#x27;min_num_params&#x27;</span>: 0, <span class="string">&#x27;xla&#x27;</span>: False, <span class="string">&#x27;xla_fsdp_grad_ckpt&#x27;</span>: False&#125;,</span><br><span class="line">fsdp_min_num_params=0,</span><br><span class="line">fsdp_transformer_layer_cls_to_wrap=None,</span><br><span class="line">full_determinism=False,</span><br><span class="line">generation_config=None,</span><br><span class="line">generation_max_length=None,</span><br><span class="line">generation_num_beams=None,</span><br><span class="line">gradient_accumulation_steps=1,</span><br><span class="line">gradient_checkpointing=False,</span><br><span class="line">gradient_checkpointing_kwargs=None,</span><br><span class="line">greater_is_better=None,</span><br><span class="line">group_by_length=False,</span><br><span class="line">half_precision_backend=auto,</span><br><span class="line">hub_always_push=False,</span><br><span class="line">hub_model_id=None,</span><br><span class="line">hub_private_repo=False,</span><br><span class="line">hub_strategy=every_save,</span><br><span class="line">hub_token=&lt;HUB_TOKEN&gt;,</span><br><span class="line">ignore_data_skip=False,</span><br><span class="line">include_inputs_for_metrics=False,</span><br><span class="line">include_tokens_per_second=False,</span><br><span class="line">jit_mode_eval=False,</span><br><span class="line">label_names=None,</span><br><span class="line">label_smoothing_factor=0.0,</span><br><span class="line">learning_rate=5e-05,</span><br><span class="line">length_column_name=length,</span><br><span class="line">load_best_model_at_end=False,</span><br><span class="line">local_rank=0,</span><br><span class="line">log_level=passive,</span><br><span class="line">log_level_replica=warning,</span><br><span class="line">log_on_each_node=True,</span><br><span class="line">logging_dir=result/runs/Dec10_11-00-58_gpu12,</span><br><span class="line">logging_first_step=False,</span><br><span class="line">logging_nan_inf_filter=True,</span><br><span class="line">logging_steps=500,</span><br><span class="line">logging_strategy=steps,</span><br><span class="line">lr_scheduler_type=linear,</span><br><span class="line">max_grad_norm=1.0,</span><br><span class="line">max_steps=-1,</span><br><span class="line">metric_for_best_model=None,</span><br><span class="line">mp_parameters=,</span><br><span class="line">neftune_noise_alpha=None,</span><br><span class="line">no_cuda=False,</span><br><span class="line">num_train_epochs=3.0,</span><br><span class="line">optim=adamw_torch,</span><br><span class="line">optim_args=None,</span><br><span class="line">output_dir=result,</span><br><span class="line">overwrite_output_dir=False,</span><br><span class="line">past_index=-1,</span><br><span class="line">per_device_eval_batch_size=192,</span><br><span class="line">per_device_train_batch_size=8,</span><br><span class="line">predict_with_generate=True,</span><br><span class="line">prediction_loss_only=False,</span><br><span class="line">push_to_hub=False,</span><br><span class="line">push_to_hub_model_id=None,</span><br><span class="line">push_to_hub_organization=None,</span><br><span class="line">push_to_hub_token=&lt;PUSH_TO_HUB_TOKEN&gt;,</span><br><span class="line">ray_scope=last,</span><br><span class="line">remove_unused_columns=True,</span><br><span class="line">report_to=[],</span><br><span class="line">resume_from_checkpoint=None,</span><br><span class="line">run_name=result,</span><br><span class="line">save_on_each_node=False,</span><br><span class="line">save_safetensors=True,</span><br><span class="line">save_steps=500,</span><br><span class="line">save_strategy=steps,</span><br><span class="line">save_total_limit=None,</span><br><span class="line">seed=42,</span><br><span class="line">skip_memory_metrics=True,</span><br><span class="line">sortish_sampler=False,</span><br><span class="line">split_batches=False,</span><br><span class="line">tf32=None,</span><br><span class="line">torch_compile=False,</span><br><span class="line">torch_compile_backend=None,</span><br><span class="line">torch_compile_mode=None,</span><br><span class="line">torchdynamo=None,</span><br><span class="line">tpu_metrics_debug=False,</span><br><span class="line">tpu_num_cores=None,</span><br><span class="line">use_cpu=False,</span><br><span class="line">use_ipex=False,</span><br><span class="line">use_legacy_prediction_loop=False,</span><br><span class="line">use_mps_device=False,</span><br><span class="line">warmup_ratio=0.0,</span><br><span class="line">warmup_steps=0,</span><br><span class="line">weight_decay=0.0,</span><br><span class="line">)</span><br><span class="line">12/10/2023 11:00:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False</span><br><span class="line">/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 <span class="built_in">which</span> will be corrected <span class="keyword">in</span> Transformers v5.</span><br><span class="line">For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.</span><br><span class="line">- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.</span><br><span class="line">- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.</span><br><span class="line">- To avoid this warning, please instantiate this tokenizer with `model_max_length` <span class="built_in">set</span> to your preferred value.</span><br><span class="line">  warnings.warn(</span><br><span class="line">Running tokenizer on prediction dataset:   0%|                                                                                    | 0/29999 [00:00&lt;?, ? examples/s]/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed <span class="keyword">in</span> v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either <span class="keyword">in</span> the same call as your input texts <span class="keyword">if</span> you use the same keyword arguments, or <span class="keyword">in</span> a separate call.</span><br><span class="line">  warnings.warn(</span><br><span class="line">Running tokenizer on prediction dataset: 100%|██████████████████████████████████████████████████████████████████████| 29999/29999 [00:13&lt;00:00, 2177.59 examples/s]</span><br><span class="line">[WARNING|logging.py:314] 2023-12-10 11:01:17,020 &gt;&gt; You<span class="string">&#x27;re using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.</span></span><br><span class="line"><span class="string">100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [09:34&lt;00:00,  3.11s/it]Traceback (most recent call last):</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;, line 654, in &lt;module&gt;</span></span><br><span class="line"><span class="string">    main()</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;, line 609, in main</span></span><br><span class="line"><span class="string">    predict_results = trainer.predict(</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer_seq2seq.py&quot;, line 228, in predict</span></span><br><span class="line"><span class="string">    return super().predict(test_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer.py&quot;, line 3087, in predict</span></span><br><span class="line"><span class="string">    output = eval_loop(</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/trainer.py&quot;, line 3304, in evaluation_loop</span></span><br><span class="line"><span class="string">    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/code/ChartQA-main/Models/T5/run_T5.py&quot;, line 541, in compute_metrics</span></span><br><span class="line"><span class="string">    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/tokenization_utils_base.py&quot;, line 3706, in batch_decode</span></span><br><span class="line"><span class="string">    return [</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/tokenization_utils_base.py&quot;, line 3707, in &lt;listcomp&gt;</span></span><br><span class="line"><span class="string">    self.decode(</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/tokenization_utils_base.py&quot;, line 3746, in decode</span></span><br><span class="line"><span class="string">    return self._decode(</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py&quot;, line 625, in _decode</span></span><br><span class="line"><span class="string">    text = self._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens)</span></span><br><span class="line"><span class="string">OverflowError: out of range integral type conversion attempted</span></span><br><span class="line"><span class="string">100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [09:35&lt;00:00,  3.66s/it]</span></span><br><span class="line"><span class="string">[2023-12-10 11:11:00,433] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2441501) of binary: /home/qyfan/anaconda3/envs/ChartQA/bin/python</span></span><br><span class="line"><span class="string">Traceback (most recent call last):</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/runpy.py&quot;, line 197, in _run_module_as_main</span></span><br><span class="line"><span class="string">    return _run_code(code, main_globals, None,</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/runpy.py&quot;, line 87, in _run_code</span></span><br><span class="line"><span class="string">    exec(code, run_globals)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/run.py&quot;, line 810, in &lt;module&gt;</span></span><br><span class="line"><span class="string">    main()</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py&quot;, line 346, in wrapper</span></span><br><span class="line"><span class="string">    return f(*args, **kwargs)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/run.py&quot;, line 806, in main</span></span><br><span class="line"><span class="string">    run(args)</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/run.py&quot;, line 797, in run</span></span><br><span class="line"><span class="string">    elastic_launch(</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/launcher/api.py&quot;, line 134, in __call__</span></span><br><span class="line"><span class="string">    return launch_agent(self._config, self._entrypoint, list(args))</span></span><br><span class="line"><span class="string">  File &quot;/home/qyfan/anaconda3/envs/ChartQA/lib/python3.9/site-packages/torch/distributed/launcher/api.py&quot;, line 264, in launch_agent</span></span><br><span class="line"><span class="string">    raise ChildFailedError(</span></span><br><span class="line"><span class="string">torch.distributed.elastic.multiprocessing.errors.ChildFailedError: </span></span><br><span class="line"><span class="string">============================================================</span></span><br><span class="line"><span class="string">run_T5.py FAILED</span></span><br><span class="line"><span class="string">------------------------------------------------------------</span></span><br><span class="line"><span class="string">Failures:</span></span><br><span class="line"><span class="string">  &lt;NO_OTHER_FAILURES&gt;</span></span><br><span class="line"><span class="string">------------------------------------------------------------</span></span><br><span class="line"><span class="string">Root Cause (first observed failure):</span></span><br><span class="line"><span class="string">[0]:</span></span><br><span class="line"><span class="string">  time      : 2023-12-10_11:11:00</span></span><br><span class="line"><span class="string">  host      : gpu12.cluster.com</span></span><br><span class="line"><span class="string">  rank      : 0 (local_rank: 0)</span></span><br><span class="line"><span class="string">  exitcode  : 1 (pid: 2441501)</span></span><br><span class="line"><span class="string">  error_file: &lt;N/A&gt;</span></span><br><span class="line"><span class="string">  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html</span></span><br><span class="line"><span class="string">============================================================</span></span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://tomatoyuan.github.io">tomatoyuan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://tomatoyuan.github.io/p/98cfd6d8.html">https://tomatoyuan.github.io/p/98cfd6d8.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://tomatoyuan.github.io" target="_blank">番茄元🍅の小窝</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/nlp/">nlp</a></div><div class="post_share"><div class="social-share" data-image="/img/bg43.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/p/42697727.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/bg115.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">李宏毅ML2022(1)</div></div></a></div><div class="next-post pull-right"><a href="/p/2106501d.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/bg104.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">ChartReader</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/p/5743e977.html" title="A Survey on Automatic Chart Understanding in the Era of Large Foundation Models"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/bg38.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-16</div><div class="title">A Survey on Automatic Chart Understanding in the Era of Large Foundation Models</div></div></a></div><div><a href="/p/e782e2a5.html" title="ChartBench"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/bg74.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-08</div><div class="title">ChartBench</div></div></a></div><div><a href="/p/9cfb766.html" title="ChartInstruct"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/bg20.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-22</div><div class="title">ChartInstruct</div></div></a></div><div><a href="/p/2106501d.html" title="ChartReader"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/bg104.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-12-16</div><div class="title">ChartReader</div></div></a></div><div><a href="/p/734809d2.html" title="PlotQA"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/bg72.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-15</div><div class="title">PlotQA</div></div></a></div><div><a href="/p/741a81c5.html" title="RealCQA"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/bg87.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-30</div><div class="title">RealCQA</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/mylogo.bmp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">tomatoyuan</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">59</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/tomatoyuan"><i class="fab fa-github"></i><span>🛴带你去我家...</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/tomatoyuan" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:Awellfrog@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content"><center>主域名：<br><a href="https://tomatoyuan.github.io"><b><font color="#5ea6e5">tomatoyuan.github.io</font></b></a></center></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#0-%E6%91%98%E8%A6%81%E7%BF%BB%E8%AF%91"><span class="toc-text">0. 摘要翻译</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-introduction"><span class="toc-text">1. INTRODUCTION</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-related-work"><span class="toc-text">2. Related Work</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-chartqa-datasets"><span class="toc-text">3. ChartQA Datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-data-collection-preparation"><span class="toc-text">3.1 Data Collection &amp; Preparation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-data-annotation"><span class="toc-text">3.2 Data Annotation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-dataset-analysis"><span class="toc-text">3.3 Dataset Analysis</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-method"><span class="toc-text">4. Method</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-problem-formulation-data-extraction"><span class="toc-text">4.1 Problem Formulation &amp; Data Extraction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-models"><span class="toc-text">4.2 Models</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-evaluation"><span class="toc-text">5. Evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-datasets-baselines-metrics"><span class="toc-text">5.1 Datasets, Baselines &amp; Metrics</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-results"><span class="toc-text">5.2 Results</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-ablation-studies"><span class="toc-text">5.3 Ablation Studies</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-qualitative-analysis"><span class="toc-text">5.4 Qualitative Analysis</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-conclusion"><span class="toc-text">6. Conclusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9C%80%E8%A6%81%E8%A1%A5%E5%85%85%E7%9A%84"><span class="toc-text">需要补充的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0"><span class="toc-text">7. 代码复现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-text">7.1 环境配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#conda-%E6%8D%A2%E6%BA%90"><span class="toc-text">conda 换源</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#pip-%E6%8D%A2%E6%BA%90"><span class="toc-text">pip 换源</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-t5%E5%A4%8D%E7%8E%B0"><span class="toc-text">7.2 T5复现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#bug2"><span class="toc-text">bug2</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By tomatoyuan</div><div class="footer_custom_text">I am a frog at the bottom of a well, but I never give up climbing up.</br>我多努力一点，我爱的人就可以多休息一会儿😊<p><a target="_blank" href="https://hexo.io/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://butterfly.js.org/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://vercel.com/ "><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vervel-brightgreen?style=flat&logo=Vercel" title="本站线路托管于Vercel"></a>&nbsp;<a target="_blank" href="https://vercel.com/ ">&nbsp;<a target="_blank" href="https://github.com/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp;<a target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a>&nbsp;<a target="_blank" href="https://icp.gov.moe/?keyword=20230070"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/%E8%90%8CICP%E5%A4%87-20230070-fe1384?style-flat&logo=data:image/png" title="萌ICP备20230070号"></a></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo-api-beta-two.vercel.app/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo-api-beta-two.vercel.app/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script defer src="/js/light.js"></script><script defer src="/js/cursor.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var qweather_key = 'c189a6faa11e45499d5f54f4af4961b9';
  var gaud_map_key = 'f373eae7d7ddbee8cd012fdc2720f4e5';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '112.982279,28.19409';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><!-- hexo injector body_end end --></body></html>